{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ae616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import git\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "import neuralpde\n",
    "\n",
    "\n",
    "SAVING = True\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as fp:\n",
    "        globals().update(pickle.load(fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6de139",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_xy = np.s_[174:235, 64:110]\n",
    "\"\"\"\n",
    "Subset of (x, y) grid to use by index, ordered as (+/- longitude, +/- latitude)\n",
    "\n",
    "# WARNING\n",
    "Ordering here is not what you expect!  Be careful to check!\n",
    "\"\"\"\n",
    "\n",
    "q = 10\n",
    "\"\"\" Number of intermediate RK stages to use. \"\"\"\n",
    "\n",
    "maps = 7\n",
    "\"\"\"\n",
    "Number of solution maps (forward and backward) to pass to PINN.\n",
    "\n",
    "Note that the total number is 2 * maps + 1.\n",
    "\"\"\"\n",
    "\n",
    "date = datetime.date(1979, 8, 15)\n",
    "# date = datetime.date(1980, 8, 15)\n",
    "# date = datetime.date(2023, 8, 15)\n",
    "\"\"\" Date to study. \"\"\"\n",
    "\n",
    "files = [\n",
    "    f'data/V4/seaice_conc_daily_nh_{date.year-1}_v04r00.nc',\n",
    "    f'data/V4/seaice_conc_daily_nh_{date.year}_v04r00.nc',\n",
    "    f'data/V4/seaice_conc_daily_nh_{date.year+1}_v04r00.nc'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9aaf01",
   "metadata": {},
   "source": [
    "Alright, let's load some data and do some preliminary checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d09301",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = neuralpde.nc.SeaIceV4(files)\n",
    "\n",
    "day = np.searchsorted(d.date, date)\n",
    "indices = np.arange(day - maps, day + maps + 1)\n",
    "\n",
    "neuralpde.nc.check_boundaries(indices, d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a23ca",
   "metadata": {},
   "source": [
    "Do some preliminary prep on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ec6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = d.seaice_conc[indices, *subset_xy]\n",
    "u[np.isnan(u)] = 0.  # mask out NaN\n",
    "\n",
    "(scalex, scaley), (x, y) = neuralpde.network.normalize_xy(d.meters_x, d.meters_y)\n",
    "x, y = np.meshgrid(x, y)  # this ordering is annoying but necessary\n",
    "x, y = x[subset_xy], y[subset_xy]\n",
    "\n",
    "mask_coast = (d.flag_coast)[day, *subset_xy]\n",
    "mask_other = (d.flag_land | d.flag_hole | d.flag_lake | d.flag_missing)[day, *subset_xy]\n",
    "mask_any = mask_coast | mask_other\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c8cb08",
   "metadata": {},
   "source": [
    "Now we define the loss hyperparameters with respect to which we will train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d56d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss hyperparameters (i.e., relative weighting of terms in loss)\n",
    "weights = np.array(\n",
    "    [\n",
    "        5.,  # differential loss (t_{n})\n",
    "        5.,  # differential loss (t_{n+1})\n",
    "        1.,  # boundary loss, no slip + no pen\n",
    "        2.,  # kappa regularization\n",
    "        2.,  # v regularization\n",
    "        4.,  # f minimization\n",
    "    ]\n",
    ")\n",
    "weights = weights / np.sqrt(np.sum(weights**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d47600",
   "metadata": {},
   "source": [
    "Now do the training.  :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148fdf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = neuralpde.network.Network(q = q, shape = u.shape, kernel = 5).to(neuralpde.network.DEVICE, neuralpde.network.DTYPE)\n",
    "losses = net.fit(x, y, u, weights, mask_coast, mask_other, epochs=1000, lr=1e-3)\n",
    "\n",
    "# compute a prediction\n",
    "uhat_i, uhat_f, kappa, kappa_x, kappa_y, v1, v1_x, v1_y, v2, v2_x, v2_y, f = net.predict(x, y, u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = git.Repo(search_parent_directories=True)\n",
    "sha = repo.head.object.hexsha[:7]\n",
    "name_slug = f'neuralpde-{date.strftime(r\"%Y%m%d\")}-{sha}.{datetime.datetime.now().strftime(r\"%Y%m%d%H%M\")}.'\n",
    "\n",
    "if SAVING:\n",
    "    torch.save(net.state_dict(), name_slug + 'weights.pth')\n",
    "\n",
    "    with open(name_slug + 'results.pkl', 'wb') as fp:\n",
    "        pickle.dump(\n",
    "            {\n",
    "                'date': date,\n",
    "                'weights': weights,\n",
    "                'losses': losses,\n",
    "                'x': x,\n",
    "                'scalex': scalex,\n",
    "                'y': y,\n",
    "                'scaley': scaley,\n",
    "                'u': u,\n",
    "                'uhat_i': uhat_i,\n",
    "                'uhat_f': uhat_f,\n",
    "                'kappa': kappa,\n",
    "                'kappa_x': kappa_x,\n",
    "                'kappa_y': kappa_y,\n",
    "                'v1': v1,\n",
    "                'v1_x': v1_x,\n",
    "                'v1_y': v1_y,\n",
    "                'v2': v2,\n",
    "                'v2_x': v2_x,\n",
    "                'v2_y': v2_y,\n",
    "                'f': f\n",
    "            },\n",
    "            fp\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_any_plotting = np.ones_like(mask_any, dtype=float)\n",
    "mask_any_plotting[mask_any] = np.nan\n",
    "\n",
    "# ice plot\n",
    "cmap = plt.get_cmap('Blues_r')\n",
    "cmap.set_bad(color='gray')\n",
    "plt.figure(figsize=(0.7 * 1.625 * 8, 1 * 8))\n",
    "plt.pcolormesh(x * scalex / 1e3, y * scaley / 1e3, u[maps] * mask_any_plotting, cmap=cmap)\n",
    "plt.colorbar().set_label('Sea Ice Concentration (fractional)')\n",
    "plt.xlabel('km from grid center (x)')\n",
    "plt.ylabel('km from grid center (y)')\n",
    "plt.title(f'{date.strftime(r\"%m/%d/%Y\")}')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "if SAVING: plt.savefig(name_slug + 'seaice-conc.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# predicted ice plot\n",
    "cmap = plt.get_cmap('Blues_r')\n",
    "cmap.set_bad(color='gray')\n",
    "plt.figure(figsize=(0.7 * 1.625 * 8, 1 * 8))\n",
    "plt.pcolormesh(x * scalex / 1e3, y * scaley / 1e3, uhat_i[-1] * mask_any_plotting, cmap=cmap)\n",
    "plt.colorbar().set_label('Sea Ice Concentration (fractional)')\n",
    "plt.xlabel('km from grid center (x)')\n",
    "plt.ylabel('km from grid center (y)')\n",
    "plt.title(f'{date.strftime(r\"%m/%d/%Y\")}')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "if SAVING: plt.savefig(name_slug + 'seaice-conc-predicted.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# error plot\n",
    "cmap = plt.get_cmap('jet')\n",
    "cmap.set_bad(color='gray')\n",
    "plt.figure(figsize=(0.7 * 1.625 * 8, 1 * 8))\n",
    "plt.pcolormesh(x * scalex / 1e3, y * scaley / 1e3, np.abs(u[maps] - uhat_f[-1]) * mask_any_plotting, cmap=cmap)\n",
    "plt.colorbar().set_label('Absolute Error')\n",
    "plt.xlabel('km from grid center (x)')\n",
    "plt.ylabel('km from grid center (y)')\n",
    "plt.title(f'{date.strftime(r\"%m/%d/%Y\")}')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "if SAVING: plt.savefig(name_slug + 'abs-err.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# parameter plots\n",
    "cmap = plt.get_cmap('jet')\n",
    "cmap.set_bad(color='gray')\n",
    "\n",
    "plt.figure(figsize=(0.7 * 1.625 * 8, 1 * 8))\n",
    "plt.pcolormesh(x * scalex / 1e3, y * scaley / 1e3, kappa * mask_any_plotting, cmap=cmap)\n",
    "plt.colorbar().set_label('Diffusivity (unitless)')\n",
    "plt.xlabel('km from grid center (x)')\n",
    "plt.ylabel('km from grid center (y)')\n",
    "plt.title(f'{date.strftime(r\"%m/%d/%Y\")}')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "if SAVING: plt.savefig(name_slug + 'kappa.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(0.7 * 1.625 * 8, 1 * 8))\n",
    "plt.pcolormesh(x * scalex / 1e3, y * scaley / 1e3, v1 * mask_any_plotting, cmap=cmap)\n",
    "plt.colorbar().set_label('Lateral Velocity (unitless)\\n(negative is left, positive is right)')\n",
    "plt.xlabel('km from grid center (x)')\n",
    "plt.ylabel('km from grid center (y)')\n",
    "plt.title(f'{date.strftime(r\"%m/%d/%Y\")}')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "if SAVING: plt.savefig(name_slug + 'v1.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(0.7 * 1.625 * 8, 1 * 8))\n",
    "plt.pcolormesh(x * scalex / 1e3, y * scaley / 1e3, v2 * mask_any_plotting, cmap=cmap)\n",
    "plt.colorbar().set_label('Vertical Velocity (unitless)\\n(negative is down, positive is up)')\n",
    "plt.xlabel('km from grid center (x)')\n",
    "plt.ylabel('km from grid center (y)')\n",
    "plt.title(f'{date.strftime(r\"%m/%d/%Y\")}')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "if SAVING: plt.savefig(name_slug + 'v2.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(0.7 * 1.625 * 8, 1 * 8))\n",
    "plt.pcolormesh(x * scalex / 1e3, y * scaley / 1e3, f * mask_any_plotting, cmap=cmap)\n",
    "plt.colorbar().set_label('Forcing (unitless)')\n",
    "plt.xlabel('km from grid center (x)')\n",
    "plt.ylabel('km from grid center (y)')\n",
    "plt.title(f'{date.strftime(r\"%m/%d/%Y\")}')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "if SAVING: plt.savefig(name_slug + 'f.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ca0ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralpde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
